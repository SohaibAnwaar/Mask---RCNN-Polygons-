{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image augmentaion:\n",
    "\n",
    "this notebook helps your to augment your annotations.\n",
    "    1. Rotate (0 - 360)\n",
    "    2. Add sharpness (random)\n",
    "    3. Add brightness (random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "vWTzvLJX61VO",
    "outputId": "9141cee5-2b4b-44e7-8a1b-580a7164acab",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/media/sohaib/additional_/DataScience/Upwork_orders/people_walk_in_zebra_crossing/Mask---RCNN-Polygons-/2_image_augmentation/utils.py\", line 168, in parse_via_json\n",
      "    region_name = list(region['region_attributes']['class'].keys())[0]\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zebra_crossing']\n",
      "Creating Images....\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "from utils import *\n",
    "\n",
    "# Directory in which images exists \n",
    "DIR_PATH = \"/media/sohaib/additional_/DataScience/Upwork_orders/people_walk_in_zebra_crossing/Mask---RCNN-Polygons-/data/zebra_crossing/\"\n",
    "\n",
    "# Json File Path\n",
    "doc_labels = \"/media/sohaib/additional_/DataScience/Upwork_orders/people_walk_in_zebra_crossing/Mask---RCNN-Polygons-/data/zebra_crossing/annotation2.json\"\n",
    "\n",
    "# Parsing Json\n",
    "images = parse_via_json(doc_labels, DIR_PATH)\n",
    "\n",
    "# Getting all of the classes from your annotations \n",
    "classes = list(set([ __ for _ in images.values() for __ in list(_.keys())]))\n",
    "print(classes)\n",
    "\n",
    "# Images you are going to augment should be greater than 1\n",
    "if len(images) <= 1:\n",
    "    print(\"I need at least 2 images\")\n",
    "    exit()\n",
    "\n",
    "# Spliting train and testing images\n",
    "total_training = int(len(images) * 0.9)\n",
    "counter = 0\n",
    "\n",
    "# Initilzing Train and val multiprocessing augmentation class\n",
    "train = Augmentation(DIR_PATH + \"/train/\")\n",
    "val = Augmentation(DIR_PATH + \"/val/\")\n",
    "\n",
    "\n",
    "# Creating images\n",
    "print(\"Creating Images....\")\n",
    "for image_path in images:\n",
    "    if  counter < total_training:\n",
    "\n",
    "        train.run(image_path, images[image_path])\n",
    "    else:\n",
    "        val.run(image_path, images[image_path])\n",
    "    counter += 1\n",
    "\n",
    "\n",
    "while train.pending > 0 or val.pending > 0:\n",
    "    print(f\"Train Pending  :{train.pending},  Validation Pending: {val.pending}\", end= '\\r')\n",
    "    \n",
    "    sleep(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Saving Labels into json\")\n",
    "save_mrcnn_labels(train.augmented_images, DIR_PATH + \"/train/via_region_data.json\", classes)\n",
    "save_mrcnn_labels(val.augmented_images, DIR_PATH + \"/val/via_region_data.json\", classes)\n",
    "file1 = open(DIR_PATH+\"labels.txt\",\"w\")\n",
    "write='\"' + '\",\"'.join(classes) + '\"'\n",
    "file1.writelines(write)\n",
    "file1.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HYZ6IuG61WD"
   },
   "source": [
    "# Validation of Augmentation\n",
    "\n",
    "Validating Images are augmentated right or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "id": "7sLyO0IK61WE",
    "outputId": "7f98c7f9-ee13-49c0-9c46-a02440b7c804",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import random\n",
    "\n",
    "# Path of augmented train path\n",
    "base_path = f'{doc_labels.rsplit(\"/\",1)[0]}/train/'\n",
    "json_file_path = f\"{base_path}/via_region_data.json\"\n",
    "labels = json.load(open(json_file_path))\n",
    "\n",
    "# Getting all of the images\n",
    "images = glob.glob(base_path + \"*.*g\")\n",
    "\n",
    "# Getting the random sample from the images\n",
    "image_list = random.sample(images,10)\n",
    "\n",
    "\n",
    "# Getting x and y and ploting the images\n",
    "for image_name in image_list:\n",
    "    object_name = image_name.rsplit(\"/\",1)[1].rsplit(\".\",1)[0]\n",
    "    img = Image.open(f'{image_name}')\n",
    "\n",
    "    points = []\n",
    "    for i in range(len(labels[f'{object_name}.json']['regions'])):\n",
    "        x = labels[f'{object_name}.json']['regions'][i]['shape_attributes']['all_points_x']\n",
    "        y = labels[f'{object_name}.json']['regions'][i]['shape_attributes']['all_points_y']\n",
    "\n",
    "        points.append(list(zip(x,y)))\n",
    "    \n",
    "    mask = make_mask(points,img.size)\n",
    "    \n",
    "    display([img , mask])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ImageAugmentation_RGB_polygons.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
